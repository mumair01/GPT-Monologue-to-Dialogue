name : inference_monologue_gpt
model_name : gpt2_null_model

load:
  model_checkpoint : gpt2
  tokenizer_checkpoint : gpt2

  ## NOTE: Uncomment to run trained model. These should be the same in finetuning.
  # There should be commented out for the null model.
  tokenizer_eos_token : <|endoftext|>
  tokenizer_pad_token : <PAD>
  tokenizer_additional_special_tokens :
    - <SP1>   # Speaker 1 token
    - <SP2>   # Speaker 2 token
    - <START> # Conversation start token
    - <END>   # Conversation end token

dataset:
  start_conv_no : 0
  end_conv_no : -1

inference:
  N : -1
  context_buffer_size : 512

