name : finetune_monologue_gpt
model_name : gpt2

load:
  model_checkpoint : gpt2
  tokenizer_checkpoint : gpt2
  tokenizer_eos_token : "<|endoftext|>"
  tokenizer_pad_token : "<PAD>"
  tokenizer_additional_special_tokens :
    - "<SP1>" # Speaker 1 token
    - "<SP2>" # Speaker 2 token
    - "<START>" # Conversation start token
    - "<END>" # Conversation end token

finetune:
  data_block_size : 128
  utterance_key : "Utterance"
  num_train_epochs : 30
  per_device_train_batch_size : 8
  per_device_eval_batch_size : 8
  warmup_steps : 300


