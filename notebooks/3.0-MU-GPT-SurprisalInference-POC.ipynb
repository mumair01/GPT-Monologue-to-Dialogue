{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof of concept for the using a finetuned GPT model to infer word probabilities \n",
    "given the previous context/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download libraries for environment. \n",
    "\n",
    "import sys \n",
    "import os \n",
    "\n",
    "# Env. vars to check if the notebook is running on colab, kaggle etc. \n",
    "IS_COLAB = \"google.colab\" in sys.modules \n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules \n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "if IS_COLAB:\n",
    "    # Install the packages \n",
    "    %pip install -q -U tensorflow-addons\n",
    "    %pip install -q -U transformers\n",
    "    %pip install -q -U datasets\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "    # Mount the drive \n",
    "    from google.colab import drive \n",
    "    drive.mount(\"/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "import random \n",
    "import shutil \n",
    "# Scikit-Learn â‰¥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "# Pytorch imports \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Others \n",
    "import glob \n",
    "\n",
    "# Transformers \n",
    "import transformers \n",
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments,AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import datasets \n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --  Set environment global vars. \n",
    "\n",
    "# Shared env. vars. \n",
    "GLOBAL_SEED = 42 \n",
    "IS_CUDA_ENV = torch.cuda.is_available()\n",
    "GLOBAL_DEVICE = torch.device('cuda') if IS_CUDA_ENV else torch.device('cpu')\n",
    "SET_SEED = True # If true, sets the global seeds for this notebook. \n",
    "\n",
    "if IS_LOCAL:\n",
    "    SMALL_MODEL = True if not IS_CUDA_ENV else False # Use a small dataset if no cuda env. \n",
    "\n",
    "if IS_COLAB:\n",
    "    SMALL_MODEL = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring env. \n",
    "if SET_SEED:\n",
    "    # to make this notebook's output stable across runs\n",
    "    np.random.seed(GLOBAL_SEED) \n",
    "    torch.manual_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Paths\n",
    "NOTEBOOK_NAME = \"gpt_inference_poc\"\n",
    "PROJECT_ROOT_DIR = \"/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue\" \n",
    "# --- Input data dirs. \n",
    "DATASET_NAME = \"daily_dialog_poc\"\n",
    "DATASET_TYPE = \"csv\"\n",
    "PROCESSED_DATA_DIR = os.path.join(PROJECT_ROOT_DIR,\"data\", \"processed\", DATASET_NAME)\n",
    "RAW_DATA_DIR = os.path.join(PROJECT_ROOT_DIR,\"data\", \"raw\", NOTEBOOK_NAME)\n",
    "\n",
    "# --- Result dirs. \n",
    "# NOTE: The model dir will have to change depending on where the models are stored. \n",
    "REPORTS_DIR = os.path.join(PROJECT_ROOT_DIR,\"reports\",NOTEBOOK_NAME)\n",
    "\n",
    "# --- Saved model / tokenizer paths \n",
    "TRAINED_MODEL_DIR = os.path.join(PROJECT_ROOT_DIR,\"models\",\"gpt_finetune_poc\",\"checkpoint-3\")\n",
    "TRAINED_TOKENIZER_DIR = os.path.join(PROJECT_ROOT_DIR,\"models\",\"gpt_finetune_poc\")\n",
    "\n",
    "os.makedirs(REPORTS_DIR,exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for GPU Support \n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to the given device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x,device) for x in data] \n",
    "    return data.to(device, non_blocking=True) \n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrapper for a dataloader to move all the data to the specified device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl \n",
    "        self.device = device \n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = \"distilgpt2\" if SMALL_MODEL else \"gpt2-large\"\n",
    "# Tokenizer vars. \n",
    "TOKENIZER_CHECKPOINT = \"gpt2\"\n",
    "TOKENIZER_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50262, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50262, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Loading the model / tokenizer \n",
    "model = AutoModelForCausalLM.from_pretrained(TRAINED_MODEL_DIR)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/models/gpt_finetune_poc', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<SP1>', '<SP2>', '<START>', '<END>']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TRAINED_TOKENIZER_DIR)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': '/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/data/processed/daily_dialog_poc/train.csv',\n",
       " 'validation': '/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/data/processed/daily_dialog_poc/validation.csv',\n",
       " 'test': '/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/data/processed/daily_dialog_poc/test.csv'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_paths = glob.glob(\"{}/*.csv\".format(PROCESSED_DATA_DIR))\n",
    "dataset_paths = {os.path.splitext(os.path.basename(p))[0] : p for p in dataset_paths}\n",
    "# Only keep the required keys / verify that they exist. \n",
    "dataset_paths = {k : dataset_paths[k] for k in ('train','validation','test')}\n",
    "dataset_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>convID</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; hey man you wanna buy some weed &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; some what &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; weed you know &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; pot ganja mary jane some chronic &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; oh umm no thanks &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; i also have blow if you prefer to do a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; no i am ok really &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; come on man i even got dope and acid try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; do you really have all of these drugs &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; where do you get them from &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; i got my connections just tell me what y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; sounds good let s see i want &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; yeah &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; i want you to put your hands behind your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;SP1&gt; the taxi drivers are on strike again &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;SP2&gt; what for &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;SP1&gt; they want the government to reduce the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;SP2&gt; it is really a hot potato &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; weve managed to reduce our energy consum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP2&gt; thats excellent &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP2&gt; how have you managed that &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; mainly because weve invested in a heat r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP2&gt; what does that mean exactly &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; well we use the exhaust gases from our p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP2&gt; what other sources of energy do you use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; we dont use any fossil fuels &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; most of our power comes from hydroelectr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; were hoping to use even more energy from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    convID                                          Utterance\n",
       "0        0                                            <START>\n",
       "1        0        <SP1> hey man you wanna buy some weed <SP1>\n",
       "2        0                              <SP2> some what <SP2>\n",
       "3        0                          <SP1> weed you know <SP1>\n",
       "4        0       <SP1> pot ganja mary jane some chronic <SP1>\n",
       "5        0                       <SP2> oh umm no thanks <SP2>\n",
       "6        0  <SP1> i also have blow if you prefer to do a f...\n",
       "7        0                      <SP2> no i am ok really <SP2>\n",
       "8        0  <SP1> come on man i even got dope and acid try...\n",
       "9        0  <SP2> do you really have all of these drugs <SP2>\n",
       "10       0             <SP2> where do you get them from <SP2>\n",
       "11       0  <SP1> i got my connections just tell me what y...\n",
       "12       0           <SP2> sounds good let s see i want <SP2>\n",
       "13       0                                   <SP1> yeah <SP1>\n",
       "14       0  <SP2> i want you to put your hands behind your...\n",
       "15       0                                              <END>\n",
       "16       1                                            <START>\n",
       "17       1   <SP1> the taxi drivers are on strike again <SP1>\n",
       "18       1                               <SP2> what for <SP2>\n",
       "19       1  <SP1> they want the government to reduce the p...\n",
       "20       1              <SP2> it is really a hot potato <SP2>\n",
       "21       1                                              <END>\n",
       "22       2                                            <START>\n",
       "23       2  <SP1> weve managed to reduce our energy consum...\n",
       "24       2                        <SP2> thats excellent <SP2>\n",
       "25       2              <SP2> how have you managed that <SP2>\n",
       "26       2  <SP1> mainly because weve invested in a heat r...\n",
       "27       2            <SP2> what does that mean exactly <SP2>\n",
       "28       2  <SP1> well we use the exhaust gases from our p...\n",
       "29       2  <SP2> what other sources of energy do you use ...\n",
       "30       2           <SP1> we dont use any fossil fuels <SP1>\n",
       "31       2  <SP1> most of our power comes from hydroelectr...\n",
       "32       2  <SP1> were hoping to use even more energy from...\n",
       "33       2                                              <END>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test dataset as a dataframe \n",
    "test_df = pd.read_csv(dataset_paths['test'],index_col=0)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE: The below should be the same in the dataset - assuming there are 2 speakers! \n",
    "SPEAKER_1_TOKEN = \"<SP1>\"\n",
    "SPEAKER_2_TOKEN = \"<SP2>\"\n",
    "CONV_START_TOKEN = \"<START>\"\n",
    "CONV_END_TOKEN = \"<END>\"\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "EOS_TOKEN = \"<|endoftext|>\"\n",
    "\n",
    "# The ID of the conversation in test.csv from where to start (included)\n",
    "START_CONVERSATION_NO = 0 \n",
    "\n",
    "# The ID of the last conversation in test.csv, -1 for all conversations.\n",
    "# NOTE: If END_CONVERSATION_NO = 80 and START_CONVERSATION_NO = 10, \n",
    "# includes conversations with IDs 10 to 79. \n",
    "END_CONVERSATION_NO = -1\n",
    "\n",
    "# Defines the number of words in each turn, from the end, for which the\n",
    "# probability is calculated.\n",
    "# NOTE: If set to -1, the probability of all the words will be calculated.\n",
    "N_PROBS = -1  # TODO: Change to -1 before running on HPC.\n",
    "\n",
    "# The maximum size, in words, of the context.\n",
    "# NOTE: Larger buffer size will increase inference time.\n",
    "CONTEXT_BUFFER_SIZE = 512 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the dataset into conversations \n",
    "conversation_dfs = [test_df.loc[test_df['convID'] == i] for i in range(np.max(test_df['convID'].unique()) + 1)]\n",
    "assert len(conversation_dfs) >= END_CONVERSATION_NO\n",
    "conversation_dfs = conversation_dfs[START_CONVERSATION_NO:END_CONVERSATION_NO]\n",
    "len(conversation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All conversations are not in separate lists \n",
    "conversation_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading and segment the data. \n",
    "\n",
    "def load_inference_dataset(csv_path, start_conv_no=START_CONVERSATION_NO, \n",
    "        end_conv_no=END_CONVERSATION_NO):\n",
    "    df = pd.read_csv(csv_path,index_col=0)\n",
    "    conversation_dfs = [df.loc[df['convID'] == i] for i in range(np.max(df['convID'].unique()) + 1)]\n",
    "    if end_conv_no > len(conversation_dfs) or end_conv_no == -1:\n",
    "        end_conv_no = len(conversation_dfs)\n",
    "    assert len(conversation_dfs) >= end_conv_no\n",
    "    assert start_conv_no < end_conv_no\n",
    "    conversation_dfs = conversation_dfs[start_conv_no:end_conv_no]\n",
    "    return conversation_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading all the conversations\n",
    "conversation_dfs = load_inference_dataset(\n",
    "    dataset_paths['test'], \n",
    "    start_conv_no=0,\n",
    "    end_conv_no=-1)\n",
    "len(conversation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading all the conversations with a very large end value. \n",
    "conversation_dfs = load_inference_dataset(\n",
    "    dataset_paths['test'], \n",
    "    start_conv_no=1,\n",
    "    end_conv_no=100)\n",
    "len(conversation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading only 1 conversation \n",
    "conversation_dfs = load_inference_dataset(\n",
    "    dataset_paths['test'], \n",
    "    start_conv_no=1,\n",
    "    end_conv_no=2)\n",
    "len(conversation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_word_prob(model, tokenizer, text):\n",
    "    sentence_so_far = text\n",
    "    context = ' '.join(text.split()[:-1])\n",
    "    # Encode\n",
    "    context_encoding = tokenizer.encode(\n",
    "        context, return_tensors=\"pt\")\n",
    "    whole_text_encoding = tokenizer.encode(\n",
    "        sentence_so_far, return_tensors=\"pt\")\n",
    "    cw_encoding = whole_text_encoding[:, context_encoding.shape[1]:]\n",
    "    output = model(whole_text_encoding)\n",
    "    # Obtain the logits for the last hidden state and the logits\n",
    "    # that provide values for the tokens in the critical word.\n",
    "    # i.e., if cw token starts at position i in the sentence, then the logits\n",
    "    # are from i-1 to len(tokens) - 1.\n",
    "    cw_extracted_logits = output.logits[-1, context_encoding.shape[1]-1:-1, :]\n",
    "    # Obtain the probabilities from the logits\n",
    "    softmax = torch.nn.Softmax(dim=-1)\n",
    "    cw_extracted_probs_from_logits = softmax(cw_extracted_logits)\n",
    "    # NOTE: Converting to log scale and taking exponential sum of the log\n",
    "    # probabilities at the end will ensure that there is not floating point\n",
    "    # overflow issue for very small probability values.\n",
    "    cw_extracted_log_probs_from_logits = torch.log(\n",
    "        cw_extracted_probs_from_logits)\n",
    "    # Extract the probabilities of the specific tokens\n",
    "    cw_tokens_probs = []\n",
    "    for cw_subtoken, probs in zip(cw_encoding[0], cw_extracted_log_probs_from_logits):\n",
    "        cw_tokens_probs.append(probs[cw_subtoken])\n",
    "    return float(torch.exp(torch.sum(torch.Tensor(cw_tokens_probs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> <SP1> the taxi drivers are on strike again <SP1> <SP2> what for <SP2> <SP1> they want the government to reduce the price of the gasoline <SP1> <SP2> it is really a hot potato <SP2>'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(conversation_dfs[0].iloc[:5][\"Utterance\"])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1585732888349357e-24"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_word_prob(model, tokenizer, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_n_word_probs(model, tokenizer, text, \n",
    "        N, context_buffer_size=CONTEXT_BUFFER_SIZE):\n",
    "    words = text.strip().split(' ')\n",
    "    if N == -1:\n",
    "        N = len(words)\n",
    "    assert not (N > len(words) or N<= 0)\n",
    "    words[:len(words) - N]\n",
    "    sentence_so_far = \" \".join(words[:len(words) - N])\n",
    "    results = []\n",
    "    for word in words[len(words) - N:]:\n",
    "        sentence_so_far += \" \" + word.strip()\n",
    "        # Reset the buffer if required \n",
    "        num_words_so_far = len(sentence_so_far.split(' '))\n",
    "        if num_words_so_far > context_buffer_size:\n",
    "            sentence_so_far = \" \".join(\n",
    "                sentence_so_far.split(' ')[num_words_so_far - context_buffer_size - 1:])\n",
    "        last_word_prob = get_last_word_prob(\n",
    "            model, tokenizer, sentence_so_far)\n",
    "        context = \" \".join(sentence_so_far.split(' ')[:-1])\n",
    "        results.append((context,word,last_word_prob))\n",
    "    return np.asarray(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> <SP1> the taxi drivers are on strike again <SP1> <SP2> what for <SP2> <SP1> they want the government to reduce the price of the gasoline <SP1> <SP2> it is really a hot potato <SP2>'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(conversation_dfs[0].iloc[:5][\"Utterance\"])\n",
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>word</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>2.834191283922965e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt;</td>\n",
       "      <td>the</td>\n",
       "      <td>3.094035994030098e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the</td>\n",
       "      <td>taxi</td>\n",
       "      <td>2.1937859952421455e-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi</td>\n",
       "      <td>drivers</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers</td>\n",
       "      <td>are</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are</td>\n",
       "      <td>on</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on</td>\n",
       "      <td>strike</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike</td>\n",
       "      <td>again</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP2&gt;</td>\n",
       "      <td>6.292495682179196e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>what</td>\n",
       "      <td>1.9010457270873804e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>for</td>\n",
       "      <td>3.4970945916703514e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP2&gt;</td>\n",
       "      <td>1.401298464324817e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>6.65673333254253e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>they</td>\n",
       "      <td>2.630904324149412e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>want</td>\n",
       "      <td>1.0880744201139427e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>the</td>\n",
       "      <td>6.336195214198952e-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>government</td>\n",
       "      <td>4.161856439044707e-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>to</td>\n",
       "      <td>3.5474571273614907e-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>reduce</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>price</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>of</td>\n",
       "      <td>1.401298464324817e-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>the</td>\n",
       "      <td>3.3385935912538767e-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP2&gt;</td>\n",
       "      <td>4.782478714734563e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>it</td>\n",
       "      <td>1.093090343310928e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>is</td>\n",
       "      <td>1.4197894071668155e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>really</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>hot</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>potato</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP2&gt;</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context        word  \\\n",
       "0                                                         <START>   \n",
       "1                                             <START>       <SP1>   \n",
       "2                                       <START> <SP1>         the   \n",
       "3                                   <START> <SP1> the        taxi   \n",
       "4                              <START> <SP1> the taxi     drivers   \n",
       "5                      <START> <SP1> the taxi drivers         are   \n",
       "6                  <START> <SP1> the taxi drivers are          on   \n",
       "7               <START> <SP1> the taxi drivers are on      strike   \n",
       "8        <START> <SP1> the taxi drivers are on strike       again   \n",
       "9    <START> <SP1> the taxi drivers are on strike ...       <SP1>   \n",
       "10   <START> <SP1> the taxi drivers are on strike ...       <SP2>   \n",
       "11   <START> <SP1> the taxi drivers are on strike ...        what   \n",
       "12   <START> <SP1> the taxi drivers are on strike ...         for   \n",
       "13   <START> <SP1> the taxi drivers are on strike ...       <SP2>   \n",
       "14   <START> <SP1> the taxi drivers are on strike ...       <SP1>   \n",
       "15   <START> <SP1> the taxi drivers are on strike ...        they   \n",
       "16   <START> <SP1> the taxi drivers are on strike ...        want   \n",
       "17   <START> <SP1> the taxi drivers are on strike ...         the   \n",
       "18   <START> <SP1> the taxi drivers are on strike ...  government   \n",
       "19   <START> <SP1> the taxi drivers are on strike ...          to   \n",
       "20   <START> <SP1> the taxi drivers are on strike ...      reduce   \n",
       "21   <START> <SP1> the taxi drivers are on strike ...         the   \n",
       "22   <START> <SP1> the taxi drivers are on strike ...       price   \n",
       "23   <START> <SP1> the taxi drivers are on strike ...          of   \n",
       "24   <START> <SP1> the taxi drivers are on strike ...         the   \n",
       "25   <START> <SP1> the taxi drivers are on strike ...    gasoline   \n",
       "26   <START> <SP1> the taxi drivers are on strike ...       <SP1>   \n",
       "27   <START> <SP1> the taxi drivers are on strike ...       <SP2>   \n",
       "28   <START> <SP1> the taxi drivers are on strike ...          it   \n",
       "29   <START> <SP1> the taxi drivers are on strike ...          is   \n",
       "30   <START> <SP1> the taxi drivers are on strike ...      really   \n",
       "31   <START> <SP1> the taxi drivers are on strike ...           a   \n",
       "32   <START> <SP1> the taxi drivers are on strike ...         hot   \n",
       "33   <START> <SP1> the taxi drivers are on strike ...      potato   \n",
       "34   <START> <SP1> the taxi drivers are on strike ...       <SP2>   \n",
       "\n",
       "                      prob  \n",
       "0                      1.0  \n",
       "1    2.834191283922965e-28  \n",
       "2    3.094035994030098e-19  \n",
       "3   2.1937859952421455e-39  \n",
       "4                      0.0  \n",
       "5                      0.0  \n",
       "6                      0.0  \n",
       "7                      0.0  \n",
       "8                      0.0  \n",
       "9                      0.0  \n",
       "10   6.292495682179196e-18  \n",
       "11  1.9010457270873804e-12  \n",
       "12  3.4970945916703514e-33  \n",
       "13   1.401298464324817e-45  \n",
       "14    6.65673333254253e-17  \n",
       "15   2.630904324149412e-14  \n",
       "16  1.0880744201139427e-34  \n",
       "17   6.336195214198952e-40  \n",
       "18   4.161856439044707e-43  \n",
       "19  3.5474571273614907e-40  \n",
       "20                     0.0  \n",
       "21                     0.0  \n",
       "22                     0.0  \n",
       "23   1.401298464324817e-44  \n",
       "24  3.3385935912538767e-41  \n",
       "25                     0.0  \n",
       "26                     0.0  \n",
       "27   4.782478714734563e-18  \n",
       "28   1.093090343310928e-14  \n",
       "29  1.4197894071668155e-32  \n",
       "30                     0.0  \n",
       "31                     0.0  \n",
       "32                     0.0  \n",
       "33                     0.0  \n",
       "34                     0.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_final_n_word_probs(model, tokenizer, text,N=-1)\n",
    "results_df = pd.DataFrame(results,columns=['context','word','prob'])\n",
    "results_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conditional_probs(model, tokenizer, conversation_df, \n",
    "        N = -1, context_buffer_size=CONTEXT_BUFFER_SIZE):\n",
    "    results_list = []\n",
    "    text = \"\"\n",
    "    for turn_no, turn in enumerate(conversation_df.itertuples()):\n",
    "        text += \" \" +  turn.Utterance.strip()\n",
    "        text = text.strip()\n",
    "        turn_length = len(turn.Utterance.split(' '))\n",
    "        n_probs = turn_length if N == -1 or N > turn_length else N \n",
    "        results = get_final_n_word_probs(\n",
    "            model, tokenizer,text,n_probs, context_buffer_size)\n",
    "        for result_no, result in enumerate(results):\n",
    "            word_no = turn_length - n_probs + result_no\n",
    "            context, word, prob = result\n",
    "            results_list.append((\n",
    "                turn.convID, turn_no, word_no, context,word,prob))\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "for conversation_df in conversation_dfs:\n",
    "    results = generate_conditional_probs(\n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "        conversation_df=conversation_df)\n",
    "    data.extend(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversationNumber</th>\n",
       "      <th>turnNumber</th>\n",
       "      <th>wordNumber</th>\n",
       "      <th>context</th>\n",
       "      <th>word</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>5.068076883288909e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt;</td>\n",
       "      <td>the</td>\n",
       "      <td>4.292436239150078e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the</td>\n",
       "      <td>taxi</td>\n",
       "      <td>2.681073475126427e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi</td>\n",
       "      <td>drivers</td>\n",
       "      <td>8.376588547418521e-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversationNumber  turnNumber  wordNumber                 context  \\\n",
       "0                   1           0           0                           \n",
       "1                   1           1           0                 <START>   \n",
       "2                   1           1           1           <START> <SP1>   \n",
       "3                   1           1           2       <START> <SP1> the   \n",
       "4                   1           1           3  <START> <SP1> the taxi   \n",
       "\n",
       "      word            probability  \n",
       "0  <START>                    1.0  \n",
       "1    <SP1>  5.068076883288909e-18  \n",
       "2      the  4.292436239150078e-25  \n",
       "3     taxi  2.681073475126427e-23  \n",
       "4  drivers  8.376588547418521e-26  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(data, columns=['conversationNumber', \n",
    "            'turnNumber','wordNumber','context','word','probability'])\n",
    "\n",
    "results_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(os.path.join(REPORTS_DIR,\"./sample_results.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a multi-threaded function when writing the script because \n",
    "# it does not work in the notebook. \n",
    "\n",
    "# from functools import partial\n",
    "# from itertools import repeat\n",
    "# from multiprocessing import Pool\n",
    "# import multiprocess as mp\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# # Generate the probs. for all conversations in a multithreaded way. \n",
    "# N = -1 \n",
    "# results_list = []\n",
    "# with mp.Pool(processes=5) as pool:\n",
    "\n",
    "#     results_list = pool.map(lambda df : generate_conditional_probs(\n",
    "#         model, tokenizer, df, N, CONTEXT_BUFFER_SIZE),conversation_dfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference in different cases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very Large Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = glob.glob(\"{}/*.csv\".format(RAW_DATA_DIR))\n",
    "dataset_paths = {os.path.splitext(os.path.basename(p))[0] : p for p in dataset_paths}\n",
    "# Only keep the required keys / verify that they exist. \n",
    "dataset_paths = {k : dataset_paths[k] for k in ('train','validation','test')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference if the input text is very large \n",
    "\n",
    "conversation_dfs = load_inference_dataset(\n",
    "    dataset_paths['test'], \n",
    "    start_conv_no=0,\n",
    "    end_conv_no=-1)\n",
    "\n",
    "# NOTE: Pretending that the last K number of conversations are part of the \n",
    "# context to make sure that the model behaves as expected when given a large \n",
    "# context. \n",
    "context_df = pd.concat(conversation_dfs[:int(len(conversation_dfs)/2)])\n",
    "large_text = \" \".join(list(context_df[\"Utterance\"]))\n",
    "# Making inference \n",
    "results = get_final_n_word_probs(model, tokenizer, text,N=10)\n",
    "results_df = pd.DataFrame(results,columns=['context','word','prob'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the text was very large, the context should have been trimmed to be \n",
    "# the context buffer size. \n",
    "assert len(results_df['context'][0].split(' ')) == CONTEXT_BUFFER_SIZE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpt_proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8226f9d8233b889d814e65b178e86bbabe6dbb1167ee6423a6522d592207fe9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
