{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof of concept for the using a finetuned GPT model to infer word probabilities \n",
    "given the previous context/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download libraries for environment. \n",
    "\n",
    "import sys \n",
    "import os \n",
    "\n",
    "# Env. vars to check if the notebook is running on colab, kaggle etc. \n",
    "IS_COLAB = \"google.colab\" in sys.modules \n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules \n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "if IS_COLAB:\n",
    "    # Install the packages \n",
    "    %pip install -q -U tensorflow-addons\n",
    "    %pip install -q -U transformers\n",
    "    %pip install -q -U datasets\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "    # Mount the drive \n",
    "    from google.colab import drive \n",
    "    drive.mount(\"/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "import random \n",
    "import shutil \n",
    "# Scikit-Learn â‰¥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "# Pytorch imports \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Others \n",
    "import glob \n",
    "\n",
    "# Transformers \n",
    "import transformers \n",
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments,AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import datasets \n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --  Set environment global vars. \n",
    "\n",
    "# Shared env. vars. \n",
    "GLOBAL_SEED = 42 \n",
    "IS_CUDA_ENV = torch.cuda.is_available()\n",
    "GLOBAL_DEVICE = torch.device('cuda') if IS_CUDA_ENV else torch.device('cpu')\n",
    "SET_SEED = True # If true, sets the global seeds for this notebook. \n",
    "\n",
    "if IS_LOCAL:\n",
    "    SMALL_MODEL = True if not IS_CUDA_ENV else False # Use a small dataset if no cuda env. \n",
    "\n",
    "if IS_COLAB:\n",
    "    SMALL_MODEL = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring env. \n",
    "if SET_SEED:\n",
    "    # to make this notebook's output stable across runs\n",
    "    np.random.seed(GLOBAL_SEED) \n",
    "    torch.manual_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Paths\n",
    "NOTEBOOK_NAME = \"gpt_inference_poc\"\n",
    "PROJECT_ROOT_DIR = \"/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue\" \n",
    "# --- Input data dirs. \n",
    "DATASET_NAME = \"daily_dialog_poc\"\n",
    "DATASET_TYPE = \"csv\"\n",
    "PROCESSED_DATA_DIR = os.path.join(PROJECT_ROOT_DIR,\"data\", \"processed\", DATASET_NAME)\n",
    "RAW_DATA_DIR = os.path.join(PROJECT_ROOT_DIR,\"data\", \"raw\", NOTEBOOK_NAME)\n",
    "\n",
    "# --- Result dirs. \n",
    "# NOTE: The model dir will have to change depending on where the models are stored. \n",
    "REPORTS_DIR = os.path.join(PROJECT_ROOT_DIR,\"reports\",NOTEBOOK_NAME)\n",
    "\n",
    "# --- Saved model / tokenizer paths \n",
    "TRAINED_MODEL_DIR = os.path.join(PROJECT_ROOT_DIR,\"models\",\"gpt_finetune_poc\",\"checkpoint-3\")\n",
    "TRAINED_TOKENIZER_DIR = os.path.join(PROJECT_ROOT_DIR,\"models\",\"gpt_finetune_poc\")\n",
    "\n",
    "os.makedirs(REPORTS_DIR,exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for GPU Support \n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to the given device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x,device) for x in data] \n",
    "    return data.to(device, non_blocking=True) \n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrapper for a dataloader to move all the data to the specified device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl \n",
    "        self.device = device \n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = \"distilgpt2\" if SMALL_MODEL else \"gpt2-large\"\n",
    "# Tokenizer vars. \n",
    "TOKENIZER_CHECKPOINT = \"gpt2\"\n",
    "TOKENIZER_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Loading the model / tokenizer \n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_CHECKPOINT)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_CHECKPOINT)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': '/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/data/processed/daily_dialog_poc/train.csv',\n",
       " 'validation': '/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/data/processed/daily_dialog_poc/validation.csv',\n",
       " 'test': '/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/data/processed/daily_dialog_poc/test.csv'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_paths = glob.glob(\"{}/*.csv\".format(PROCESSED_DATA_DIR))\n",
    "dataset_paths = {os.path.splitext(os.path.basename(p))[0] : p for p in dataset_paths}\n",
    "# Only keep the required keys / verify that they exist. \n",
    "dataset_paths = {k : dataset_paths[k] for k in ('train','validation','test')}\n",
    "dataset_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>convID</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; hey man you wanna buy some weed &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; some what &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; weed you know &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; pot ganja mary jane some chronic &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; oh umm no thanks &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; i also have blow if you prefer to do a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; no i am ok really &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; come on man i even got dope and acid try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; do you really have all of these drugs &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; where do you get them from &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; i got my connections just tell me what y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; sounds good let s see i want &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; yeah &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; i want you to put your hands behind your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;SP1&gt; the taxi drivers are on strike again &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;SP2&gt; what for &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;SP1&gt; they want the government to reduce the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;SP2&gt; it is really a hot potato &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; weve managed to reduce our energy consum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP2&gt; thats excellent &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP2&gt; how have you managed that &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; mainly because weve invested in a heat r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP2&gt; what does that mean exactly &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; well we use the exhaust gases from our p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP2&gt; what other sources of energy do you use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; we dont use any fossil fuels &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; most of our power comes from hydroelectr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SP1&gt; were hoping to use even more energy from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    convID                                          Utterance\n",
       "0        0                                            <START>\n",
       "1        0        <SP1> hey man you wanna buy some weed <SP1>\n",
       "2        0                              <SP2> some what <SP2>\n",
       "3        0                          <SP1> weed you know <SP1>\n",
       "4        0       <SP1> pot ganja mary jane some chronic <SP1>\n",
       "5        0                       <SP2> oh umm no thanks <SP2>\n",
       "6        0  <SP1> i also have blow if you prefer to do a f...\n",
       "7        0                      <SP2> no i am ok really <SP2>\n",
       "8        0  <SP1> come on man i even got dope and acid try...\n",
       "9        0  <SP2> do you really have all of these drugs <SP2>\n",
       "10       0             <SP2> where do you get them from <SP2>\n",
       "11       0  <SP1> i got my connections just tell me what y...\n",
       "12       0           <SP2> sounds good let s see i want <SP2>\n",
       "13       0                                   <SP1> yeah <SP1>\n",
       "14       0  <SP2> i want you to put your hands behind your...\n",
       "15       0                                              <END>\n",
       "16       1                                            <START>\n",
       "17       1   <SP1> the taxi drivers are on strike again <SP1>\n",
       "18       1                               <SP2> what for <SP2>\n",
       "19       1  <SP1> they want the government to reduce the p...\n",
       "20       1              <SP2> it is really a hot potato <SP2>\n",
       "21       1                                              <END>\n",
       "22       2                                            <START>\n",
       "23       2  <SP1> weve managed to reduce our energy consum...\n",
       "24       2                        <SP2> thats excellent <SP2>\n",
       "25       2              <SP2> how have you managed that <SP2>\n",
       "26       2  <SP1> mainly because weve invested in a heat r...\n",
       "27       2            <SP2> what does that mean exactly <SP2>\n",
       "28       2  <SP1> well we use the exhaust gases from our p...\n",
       "29       2  <SP2> what other sources of energy do you use ...\n",
       "30       2           <SP1> we dont use any fossil fuels <SP1>\n",
       "31       2  <SP1> most of our power comes from hydroelectr...\n",
       "32       2  <SP1> were hoping to use even more energy from...\n",
       "33       2                                              <END>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test dataset as a dataframe \n",
    "test_df = pd.read_csv(dataset_paths['test'],index_col=0)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE: The below should be the same in the dataset - assuming there are 2 speakers! \n",
    "SPEAKER_1_TOKEN = \"<SP1>\"\n",
    "SPEAKER_2_TOKEN = \"<SP2>\"\n",
    "CONV_START_TOKEN = \"<START>\"\n",
    "CONV_END_TOKEN = \"<END>\"\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "EOS_TOKEN = \"<|endoftext|>\"\n",
    "\n",
    "# The ID of the conversation in test.csv from where to start (included)\n",
    "START_CONVERSATION_NO = 0 \n",
    "\n",
    "# The ID of the last conversation in test.csv, -1 for all conversations.\n",
    "# NOTE: If END_CONVERSATION_NO = 80 and START_CONVERSATION_NO = 10, \n",
    "# includes conversations with IDs 10 to 79. \n",
    "END_CONVERSATION_NO = -1\n",
    "\n",
    "# Defines the number of words in each turn, from the end, for which the\n",
    "# probability is calculated.\n",
    "# NOTE: If set to -1, the probability of all the words will be calculated.\n",
    "N_PROBS = -1  # TODO: Change to -1 before running on HPC.\n",
    "\n",
    "# The maximum size, in words, of the context.\n",
    "# NOTE: Larger buffer size will increase inference time.\n",
    "CONTEXT_BUFFER_SIZE = 512 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segment the dataset into conversations \n",
    "conversation_dfs = [test_df.loc[test_df['convID'] == i] for i in range(np.max(test_df['convID'].unique()) + 1)]\n",
    "assert len(conversation_dfs) >= END_CONVERSATION_NO\n",
    "conversation_dfs = conversation_dfs[START_CONVERSATION_NO:END_CONVERSATION_NO]\n",
    "len(conversation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>convID</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; hey man you wanna buy some weed &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; some what &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; weed you know &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; pot ganja mary jane some chronic &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; oh umm no thanks &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; i also have blow if you prefer to do a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; no i am ok really &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; come on man i even got dope and acid try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; do you really have all of these drugs &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; where do you get them from &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; i got my connections just tell me what y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; sounds good let s see i want &lt;SP2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP1&gt; yeah &lt;SP1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SP2&gt; i want you to put your hands behind your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    convID                                          Utterance\n",
       "0        0                                            <START>\n",
       "1        0        <SP1> hey man you wanna buy some weed <SP1>\n",
       "2        0                              <SP2> some what <SP2>\n",
       "3        0                          <SP1> weed you know <SP1>\n",
       "4        0       <SP1> pot ganja mary jane some chronic <SP1>\n",
       "5        0                       <SP2> oh umm no thanks <SP2>\n",
       "6        0  <SP1> i also have blow if you prefer to do a f...\n",
       "7        0                      <SP2> no i am ok really <SP2>\n",
       "8        0  <SP1> come on man i even got dope and acid try...\n",
       "9        0  <SP2> do you really have all of these drugs <SP2>\n",
       "10       0             <SP2> where do you get them from <SP2>\n",
       "11       0  <SP1> i got my connections just tell me what y...\n",
       "12       0           <SP2> sounds good let s see i want <SP2>\n",
       "13       0                                   <SP1> yeah <SP1>\n",
       "14       0  <SP2> i want you to put your hands behind your...\n",
       "15       0                                              <END>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All conversations are not in separate lists \n",
    "conversation_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading and segment the data. \n",
    "\n",
    "def load_inference_dataset(csv_path, start_conv_no=START_CONVERSATION_NO, \n",
    "        end_conv_no=END_CONVERSATION_NO):\n",
    "    df = pd.read_csv(csv_path,index_col=0)\n",
    "    conversation_dfs = [df.loc[df['convID'] == i] for i in range(np.max(df['convID'].unique()) + 1)]\n",
    "    if end_conv_no > len(conversation_dfs) or end_conv_no == -1:\n",
    "        end_conv_no = len(conversation_dfs)\n",
    "    assert len(conversation_dfs) >= end_conv_no\n",
    "    assert start_conv_no < end_conv_no\n",
    "    conversation_dfs = conversation_dfs[start_conv_no:end_conv_no]\n",
    "    return conversation_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading all the conversations\n",
    "conversation_dfs = load_inference_dataset(\n",
    "    dataset_paths['test'], \n",
    "    start_conv_no=0,\n",
    "    end_conv_no=-1)\n",
    "len(conversation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading all the conversations with a very large end value. \n",
    "conversation_dfs = load_inference_dataset(\n",
    "    dataset_paths['test'], \n",
    "    start_conv_no=1,\n",
    "    end_conv_no=100)\n",
    "len(conversation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading only 1 conversation \n",
    "conversation_dfs = load_inference_dataset(\n",
    "    dataset_paths['test'], \n",
    "    start_conv_no=1,\n",
    "    end_conv_no=2)\n",
    "len(conversation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_word_prob(model, tokenizer, text):\n",
    "    sentence_so_far = text\n",
    "    context = ' '.join(text.split()[:-1])\n",
    "    # Encode\n",
    "    context_encoding = tokenizer.encode(\n",
    "        context, return_tensors=\"pt\")\n",
    "    whole_text_encoding = tokenizer.encode(\n",
    "        sentence_so_far, return_tensors=\"pt\")\n",
    "    cw_encoding = whole_text_encoding[:, context_encoding.shape[1]:]\n",
    "    output = model(whole_text_encoding)\n",
    "    # Obtain the logits for the last hidden state and the logits\n",
    "    # that provide values for the tokens in the critical word.\n",
    "    # i.e., if cw token starts at position i in the sentence, then the logits\n",
    "    # are from i-1 to len(tokens) - 1.\n",
    "    cw_extracted_logits = output.logits[-1, context_encoding.shape[1]-1:-1, :]\n",
    "    # Obtain the probabilities from the logits\n",
    "    softmax = torch.nn.Softmax(dim=-1)\n",
    "    cw_extracted_probs_from_logits = softmax(cw_extracted_logits)\n",
    "    # NOTE: Converting to log scale and taking exponential sum of the log\n",
    "    # probabilities at the end will ensure that there is not floating point\n",
    "    # overflow issue for very small probability values.\n",
    "    cw_extracted_log_probs_from_logits = torch.log(\n",
    "        cw_extracted_probs_from_logits)\n",
    "    # Extract the probabilities of the specific tokens\n",
    "    cw_tokens_probs = []\n",
    "    for cw_subtoken, probs in zip(cw_encoding[0], cw_extracted_log_probs_from_logits):\n",
    "        cw_tokens_probs.append(probs[cw_subtoken])\n",
    "    return float(torch.exp(torch.sum(torch.Tensor(cw_tokens_probs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> <SP1> the taxi drivers are on strike again <SP1> <SP2> what for <SP2> <SP1> they want the government to reduce the price of the gasoline <SP1> <SP2> it is really a hot potato <SP2>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(conversation_dfs[0].iloc[:5][\"Utterance\"])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3585963547229767"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_word_prob(model, tokenizer, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_n_word_probs(model, tokenizer, text, \n",
    "        N, context_buffer_size=CONTEXT_BUFFER_SIZE):\n",
    "    words = text.strip().split(' ')\n",
    "    if N == -1:\n",
    "        N = len(words)\n",
    "    assert not (N > len(words) or N<= 0)\n",
    "    words[:len(words) - N]\n",
    "    sentence_so_far = \" \".join(words[:len(words) - N])\n",
    "    results = []\n",
    "    for word in words[len(words) - N:]:\n",
    "        sentence_so_far += \" \" + word.strip()\n",
    "        # Reset the buffer if required \n",
    "        num_words_so_far = len(sentence_so_far.split(' '))\n",
    "        if num_words_so_far > context_buffer_size:\n",
    "            sentence_so_far = \" \".join(\n",
    "                sentence_so_far.split(' ')[num_words_so_far - context_buffer_size - 1:])\n",
    "        last_word_prob = get_last_word_prob(\n",
    "            model, tokenizer, sentence_so_far)\n",
    "        context = \" \".join(sentence_so_far.split(' ')[:-1])\n",
    "        results.append((context,word,last_word_prob))\n",
    "    return np.asarray(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> <SP1> the taxi drivers are on strike again <SP1> <SP2> what for <SP2> <SP1> they want the government to reduce the price of the gasoline <SP1> <SP2> it is really a hot potato <SP2>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(conversation_dfs[0].iloc[:5][\"Utterance\"])\n",
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>word</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>1.741062646942737e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt;</td>\n",
       "      <td>the</td>\n",
       "      <td>0.0003473897813819349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the</td>\n",
       "      <td>taxi</td>\n",
       "      <td>9.723034963826649e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi</td>\n",
       "      <td>drivers</td>\n",
       "      <td>0.010217800736427307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers</td>\n",
       "      <td>are</td>\n",
       "      <td>0.11804268509149551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are</td>\n",
       "      <td>on</td>\n",
       "      <td>0.009845024906098843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on</td>\n",
       "      <td>strike</td>\n",
       "      <td>0.012676797807216644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike</td>\n",
       "      <td>again</td>\n",
       "      <td>0.006491983775049448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>0.021170100197196007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP2&gt;</td>\n",
       "      <td>0.013483703136444092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>what</td>\n",
       "      <td>0.002015698468312621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>for</td>\n",
       "      <td>0.0010977190686389804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP2&gt;</td>\n",
       "      <td>0.001484140520915389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>0.003414503298699856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>they</td>\n",
       "      <td>0.01980353519320488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>want</td>\n",
       "      <td>0.026359502226114273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.03870922699570656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>government</td>\n",
       "      <td>0.003537561511620879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>to</td>\n",
       "      <td>0.8553115129470825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>reduce</td>\n",
       "      <td>0.001655012252740562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.2160605937242508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>price</td>\n",
       "      <td>0.015152634121477604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>of</td>\n",
       "      <td>0.6249443292617798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.0588967427611351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>0.0003157604078296572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>0.0021431383211165667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP2&gt;</td>\n",
       "      <td>0.7649946212768555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>it</td>\n",
       "      <td>0.002183485310524702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>is</td>\n",
       "      <td>0.19015075266361237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>really</td>\n",
       "      <td>0.008788291364908218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0645408108830452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>hot</td>\n",
       "      <td>0.0006931247189640999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>potato</td>\n",
       "      <td>0.003928188234567642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi drivers are on strike ...</td>\n",
       "      <td>&lt;SP2&gt;</td>\n",
       "      <td>0.3756764829158783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context        word  \\\n",
       "0                                                         <START>   \n",
       "1                                             <START>       <SP1>   \n",
       "2                                       <START> <SP1>         the   \n",
       "3                                   <START> <SP1> the        taxi   \n",
       "4                              <START> <SP1> the taxi     drivers   \n",
       "5                      <START> <SP1> the taxi drivers         are   \n",
       "6                  <START> <SP1> the taxi drivers are          on   \n",
       "7               <START> <SP1> the taxi drivers are on      strike   \n",
       "8        <START> <SP1> the taxi drivers are on strike       again   \n",
       "9    <START> <SP1> the taxi drivers are on strike ...       <SP1>   \n",
       "10   <START> <SP1> the taxi drivers are on strike ...       <SP2>   \n",
       "11   <START> <SP1> the taxi drivers are on strike ...        what   \n",
       "12   <START> <SP1> the taxi drivers are on strike ...         for   \n",
       "13   <START> <SP1> the taxi drivers are on strike ...       <SP2>   \n",
       "14   <START> <SP1> the taxi drivers are on strike ...       <SP1>   \n",
       "15   <START> <SP1> the taxi drivers are on strike ...        they   \n",
       "16   <START> <SP1> the taxi drivers are on strike ...        want   \n",
       "17   <START> <SP1> the taxi drivers are on strike ...         the   \n",
       "18   <START> <SP1> the taxi drivers are on strike ...  government   \n",
       "19   <START> <SP1> the taxi drivers are on strike ...          to   \n",
       "20   <START> <SP1> the taxi drivers are on strike ...      reduce   \n",
       "21   <START> <SP1> the taxi drivers are on strike ...         the   \n",
       "22   <START> <SP1> the taxi drivers are on strike ...       price   \n",
       "23   <START> <SP1> the taxi drivers are on strike ...          of   \n",
       "24   <START> <SP1> the taxi drivers are on strike ...         the   \n",
       "25   <START> <SP1> the taxi drivers are on strike ...    gasoline   \n",
       "26   <START> <SP1> the taxi drivers are on strike ...       <SP1>   \n",
       "27   <START> <SP1> the taxi drivers are on strike ...       <SP2>   \n",
       "28   <START> <SP1> the taxi drivers are on strike ...          it   \n",
       "29   <START> <SP1> the taxi drivers are on strike ...          is   \n",
       "30   <START> <SP1> the taxi drivers are on strike ...      really   \n",
       "31   <START> <SP1> the taxi drivers are on strike ...           a   \n",
       "32   <START> <SP1> the taxi drivers are on strike ...         hot   \n",
       "33   <START> <SP1> the taxi drivers are on strike ...      potato   \n",
       "34   <START> <SP1> the taxi drivers are on strike ...       <SP2>   \n",
       "\n",
       "                     prob  \n",
       "0                     1.0  \n",
       "1   1.741062646942737e-06  \n",
       "2   0.0003473897813819349  \n",
       "3   9.723034963826649e-06  \n",
       "4    0.010217800736427307  \n",
       "5     0.11804268509149551  \n",
       "6    0.009845024906098843  \n",
       "7    0.012676797807216644  \n",
       "8    0.006491983775049448  \n",
       "9    0.021170100197196007  \n",
       "10   0.013483703136444092  \n",
       "11   0.002015698468312621  \n",
       "12  0.0010977190686389804  \n",
       "13   0.001484140520915389  \n",
       "14   0.003414503298699856  \n",
       "15    0.01980353519320488  \n",
       "16   0.026359502226114273  \n",
       "17    0.03870922699570656  \n",
       "18   0.003537561511620879  \n",
       "19     0.8553115129470825  \n",
       "20   0.001655012252740562  \n",
       "21     0.2160605937242508  \n",
       "22   0.015152634121477604  \n",
       "23     0.6249443292617798  \n",
       "24     0.0588967427611351  \n",
       "25  0.0003157604078296572  \n",
       "26  0.0021431383211165667  \n",
       "27     0.7649946212768555  \n",
       "28   0.002183485310524702  \n",
       "29    0.19015075266361237  \n",
       "30   0.008788291364908218  \n",
       "31     0.0645408108830452  \n",
       "32  0.0006931247189640999  \n",
       "33   0.003928188234567642  \n",
       "34     0.3756764829158783  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_final_n_word_probs(model, tokenizer, text,N=-1)\n",
    "results_df = pd.DataFrame(results,columns=['context','word','prob'])\n",
    "results_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conditional_probs(model, tokenizer, conversation_df, \n",
    "        N = -1, context_buffer_size=CONTEXT_BUFFER_SIZE):\n",
    "    results_list = []\n",
    "    text = \"\"\n",
    "    for turn_no, turn in enumerate(conversation_df.itertuples()):\n",
    "        text += \" \" +  turn.Utterance.strip()\n",
    "        text = text.strip()\n",
    "        turn_length = len(turn.Utterance.split(' '))\n",
    "        n_probs = turn_length if N == -1 or N > turn_length else N \n",
    "        results = get_final_n_word_probs(\n",
    "            model, tokenizer,text,n_probs, context_buffer_size)\n",
    "        for result_no, result in enumerate(results):\n",
    "            word_no = turn_length - n_probs + result_no\n",
    "            context, word, prob = result\n",
    "            results_list.append((\n",
    "                turn.convID, turn_no, word_no, context,word,prob))\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "for conversation_df in conversation_dfs:\n",
    "    results = generate_conditional_probs(\n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "        conversation_df=conversation_df)\n",
    "    data.extend(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversationNumber</th>\n",
       "      <th>turnNumber</th>\n",
       "      <th>wordNumber</th>\n",
       "      <th>context</th>\n",
       "      <th>word</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>&lt;SP1&gt;</td>\n",
       "      <td>3.432197900110623e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt;</td>\n",
       "      <td>the</td>\n",
       "      <td>0.00027911263168789446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the</td>\n",
       "      <td>taxi</td>\n",
       "      <td>6.538627530972008e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;START&gt; &lt;SP1&gt; the taxi</td>\n",
       "      <td>drivers</td>\n",
       "      <td>0.009760499931871891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversationNumber  turnNumber  wordNumber                 context  \\\n",
       "0                   1           0           0                           \n",
       "1                   1           1           0                 <START>   \n",
       "2                   1           1           1           <START> <SP1>   \n",
       "3                   1           1           2       <START> <SP1> the   \n",
       "4                   1           1           3  <START> <SP1> the taxi   \n",
       "\n",
       "      word             probability  \n",
       "0  <START>                     1.0  \n",
       "1    <SP1>   3.432197900110623e-06  \n",
       "2      the  0.00027911263168789446  \n",
       "3     taxi   6.538627530972008e-06  \n",
       "4  drivers    0.009760499931871891  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(data, columns=['conversationNumber', \n",
    "            'turnNumber','wordNumber','context','word','probability'])\n",
    "\n",
    "results_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(os.path.join(REPORTS_DIR,\"./sample_results.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a multi-threaded function when writing the script because \n",
    "# it does not work in the notebook. \n",
    "\n",
    "# from functools import partial\n",
    "# from itertools import repeat\n",
    "# from multiprocessing import Pool\n",
    "# import multiprocess as mp\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# # Generate the probs. for all conversations in a multithreaded way. \n",
    "# N = -1 \n",
    "# results_list = []\n",
    "# with mp.Pool(processes=5) as pool:\n",
    "\n",
    "#     results_list = pool.map(lambda df : generate_conditional_probs(\n",
    "#         model, tokenizer, df, N, CONTEXT_BUFFER_SIZE),conversation_dfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference in different cases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very Large Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = glob.glob(\"{}/*.csv\".format(RAW_DATA_DIR))\n",
    "dataset_paths = {os.path.splitext(os.path.basename(p))[0] : p for p in dataset_paths}\n",
    "# Only keep the required keys / verify that they exist. \n",
    "dataset_paths = {k : dataset_paths[k] for k in ('train','validation','test')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference if the input text is very large \n",
    "\n",
    "conversation_dfs = load_inference_dataset(\n",
    "    dataset_paths['test'], \n",
    "    start_conv_no=0,\n",
    "    end_conv_no=-1)\n",
    "\n",
    "# NOTE: Pretending that the last K number of conversations are part of the \n",
    "# context to make sure that the model behaves as expected when given a large \n",
    "# context. \n",
    "context_df = pd.concat(conversation_dfs[:int(len(conversation_dfs)/2)])\n",
    "large_text = \" \".join(list(context_df[\"Utterance\"]))\n",
    "# Making inference \n",
    "results = get_final_n_word_probs(model, tokenizer, text,N=10)\n",
    "results_df = pd.DataFrame(results,columns=['context','word','prob'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/notebooks/3.0-MU-GPT-SurprisalInference-POC.ipynb Cell 41'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/notebooks/3.0-MU-GPT-SurprisalInference-POC.ipynb#ch0000040?line=0'>1</a>\u001b[0m \u001b[39m# Since the text was very large, the context should have been trimmed to be \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/notebooks/3.0-MU-GPT-SurprisalInference-POC.ipynb#ch0000040?line=1'>2</a>\u001b[0m \u001b[39m# the context buffer size. \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/muhammadumair/Documents/Repositories/mumair01-repos/GPT-Monologue-to-Dialogue/notebooks/3.0-MU-GPT-SurprisalInference-POC.ipynb#ch0000040?line=2'>3</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(results_df[\u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m==\u001b[39m CONTEXT_BUFFER_SIZE\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Since the text was very large, the context should have been trimmed to be \n",
    "# the context buffer size. \n",
    "assert len(results_df['context'][0].split(' ')) == CONTEXT_BUFFER_SIZE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpt_proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8226f9d8233b889d814e65b178e86bbabe6dbb1167ee6423a6522d592207fe9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
